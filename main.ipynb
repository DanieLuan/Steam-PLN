{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 01\n",
    "\n",
    "Grupo: Breno Ferreira, Daniel Luan, Gabriel Bessa, Renato Palmiery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapas\n",
    "\n",
    "- Escolha Dataset\n",
    "- Entendendo o Dataset\n",
    "- Tratamento Inicial\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolha Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/daniel/ufrn/pln/atividade_01/main.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/daniel/ufrn/pln/atividade_01/main.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m steam_review_list\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/daniel/ufrn/pln/atividade_01/main.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m steam_review_list \u001b[39m=\u001b[39m get_steam_review_json()\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/daniel/ufrn/pln/atividade_01/main.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mjson_normalize(steam_review_list)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/daniel/ufrn/pln/atividade_01/main.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m df\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_normalize.py:459\u001b[0m, in \u001b[0;36mjson_normalize\u001b[0;34m(data, record_path, meta, meta_prefix, record_prefix, errors, sep, max_level)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m# check to see if a simple recursive function is possible to\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m# improve performance (see #15621) but only for cases such\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39m# as pd.Dataframe(data) or pd.Dataframe(data, sep)\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    453\u001b[0m     record_path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[39mand\u001b[39;00m meta \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[39mand\u001b[39;00m max_level \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    458\u001b[0m ):\n\u001b[0;32m--> 459\u001b[0m     \u001b[39mreturn\u001b[39;00m DataFrame(_simple_json_normalize(data, sep\u001b[39m=\u001b[39;49msep))\n\u001b[1;32m    461\u001b[0m \u001b[39mif\u001b[39;00m record_path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m([\u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m y\u001b[39m.\u001b[39mvalues()] \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m data):\n\u001b[1;32m    463\u001b[0m         \u001b[39m# naive normalization, this is idempotent for flat records\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[39m# and potentially will inflate the data considerably for\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[39m# TODO: handle record value which are lists, at least error\u001b[39;00m\n\u001b[1;32m    469\u001b[0m         \u001b[39m#       reasonably\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_normalize.py:242\u001b[0m, in \u001b[0;36m_simple_json_normalize\u001b[0;34m(ds, sep)\u001b[0m\n\u001b[1;32m    240\u001b[0m     normalised_json_object \u001b[39m=\u001b[39m _normalise_json_ordered(data\u001b[39m=\u001b[39mds, separator\u001b[39m=\u001b[39msep)\n\u001b[1;32m    241\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(ds, \u001b[39mlist\u001b[39m):\n\u001b[0;32m--> 242\u001b[0m     normalised_json_list \u001b[39m=\u001b[39m [_simple_json_normalize(row, sep\u001b[39m=\u001b[39msep) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m ds]\n\u001b[1;32m    243\u001b[0m     \u001b[39mreturn\u001b[39;00m normalised_json_list\n\u001b[1;32m    244\u001b[0m \u001b[39mreturn\u001b[39;00m normalised_json_object\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_normalize.py:242\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    240\u001b[0m     normalised_json_object \u001b[39m=\u001b[39m _normalise_json_ordered(data\u001b[39m=\u001b[39mds, separator\u001b[39m=\u001b[39msep)\n\u001b[1;32m    241\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(ds, \u001b[39mlist\u001b[39m):\n\u001b[0;32m--> 242\u001b[0m     normalised_json_list \u001b[39m=\u001b[39m [_simple_json_normalize(row, sep\u001b[39m=\u001b[39;49msep) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m ds]\n\u001b[1;32m    243\u001b[0m     \u001b[39mreturn\u001b[39;00m normalised_json_list\n\u001b[1;32m    244\u001b[0m \u001b[39mreturn\u001b[39;00m normalised_json_object\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_normalize.py:240\u001b[0m, in \u001b[0;36m_simple_json_normalize\u001b[0;34m(ds, sep)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39m# expect a dictionary, as most jsons are. However, lists are perfectly valid\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ds, \u001b[39mdict\u001b[39m):\n\u001b[0;32m--> 240\u001b[0m     normalised_json_object \u001b[39m=\u001b[39m _normalise_json_ordered(data\u001b[39m=\u001b[39;49mds, separator\u001b[39m=\u001b[39;49msep)\n\u001b[1;32m    241\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(ds, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    242\u001b[0m     normalised_json_list \u001b[39m=\u001b[39m [_simple_json_normalize(row, sep\u001b[39m=\u001b[39msep) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m ds]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_normalize.py:185\u001b[0m, in \u001b[0;36m_normalise_json_ordered\u001b[0;34m(data, separator)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39mOrder the top level keys and then recursively go to depth\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39mdict or list of dicts, matching `normalised_json_object`\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m top_dict_ \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(v, \u001b[39mdict\u001b[39m)}\n\u001b[0;32m--> 185\u001b[0m nested_dict_ \u001b[39m=\u001b[39m _normalise_json(\n\u001b[1;32m    186\u001b[0m     data\u001b[39m=\u001b[39;49m{k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m data\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(v, \u001b[39mdict\u001b[39;49m)},\n\u001b[1;32m    187\u001b[0m     key_string\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    188\u001b[0m     normalized_dict\u001b[39m=\u001b[39;49m{},\n\u001b[1;32m    189\u001b[0m     separator\u001b[39m=\u001b[39;49mseparator,\n\u001b[1;32m    190\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtop_dict_, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnested_dict_}\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_normalize.py:158\u001b[0m, in \u001b[0;36m_normalise_json\u001b[0;34m(data, key_string, normalized_dict, separator)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m                 new_key \u001b[39m=\u001b[39m new_key\u001b[39m.\u001b[39mremoveprefix(separator)\n\u001b[0;32m--> 158\u001b[0m         _normalise_json(\n\u001b[1;32m    159\u001b[0m             data\u001b[39m=\u001b[39;49mvalue,\n\u001b[1;32m    160\u001b[0m             key_string\u001b[39m=\u001b[39;49mnew_key,\n\u001b[1;32m    161\u001b[0m             normalized_dict\u001b[39m=\u001b[39;49mnormalized_dict,\n\u001b[1;32m    162\u001b[0m             separator\u001b[39m=\u001b[39;49mseparator,\n\u001b[1;32m    163\u001b[0m         )\n\u001b[1;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     normalized_dict[key_string] \u001b[39m=\u001b[39m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_normalize.py:158\u001b[0m, in \u001b[0;36m_normalise_json\u001b[0;34m(data, key_string, normalized_dict, separator)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m                 new_key \u001b[39m=\u001b[39m new_key\u001b[39m.\u001b[39mremoveprefix(separator)\n\u001b[0;32m--> 158\u001b[0m         _normalise_json(\n\u001b[1;32m    159\u001b[0m             data\u001b[39m=\u001b[39;49mvalue,\n\u001b[1;32m    160\u001b[0m             key_string\u001b[39m=\u001b[39;49mnew_key,\n\u001b[1;32m    161\u001b[0m             normalized_dict\u001b[39m=\u001b[39;49mnormalized_dict,\n\u001b[1;32m    162\u001b[0m             separator\u001b[39m=\u001b[39;49mseparator,\n\u001b[1;32m    163\u001b[0m         )\n\u001b[1;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     normalized_dict[key_string] \u001b[39m=\u001b[39m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_normalize.py:158\u001b[0m, in \u001b[0;36m_normalise_json\u001b[0;34m(data, key_string, normalized_dict, separator)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m                 new_key \u001b[39m=\u001b[39m new_key\u001b[39m.\u001b[39mremoveprefix(separator)\n\u001b[0;32m--> 158\u001b[0m         _normalise_json(\n\u001b[1;32m    159\u001b[0m             data\u001b[39m=\u001b[39;49mvalue,\n\u001b[1;32m    160\u001b[0m             key_string\u001b[39m=\u001b[39;49mnew_key,\n\u001b[1;32m    161\u001b[0m             normalized_dict\u001b[39m=\u001b[39;49mnormalized_dict,\n\u001b[1;32m    162\u001b[0m             separator\u001b[39m=\u001b[39;49mseparator,\n\u001b[1;32m    163\u001b[0m         )\n\u001b[1;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     normalized_dict[key_string] \u001b[39m=\u001b[39m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_normalize.py:146\u001b[0m, in \u001b[0;36m_normalise_json\u001b[0;34m(data, key_string, normalized_dict, separator)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_normalise_json\u001b[39m(\n\u001b[1;32m    124\u001b[0m     data: Any,\n\u001b[1;32m    125\u001b[0m     key_string: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    126\u001b[0m     normalized_dict: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m    127\u001b[0m     separator: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    128\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m    129\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m    Main recursive function\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    Designed for the most basic use case of pd.json_normalize(data)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39m        e.g., for sep='.', { 'foo' : { 'bar' : 0 } } -> foo.bar\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39;49m(data, \u001b[39mdict\u001b[39;49m):\n\u001b[1;32m    147\u001b[0m         \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    148\u001b[0m             new_key \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkey_string\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mseparator\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "def get_steam_review_json():\n",
    "    steam_review_list = []\n",
    "    dir = 'datasets/steam_reviews_cruas'\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                with open(f\"{root}/{file}\") as json_file:\n",
    "                    fileJson = json.load(json_file)\n",
    "                    steam_review_list.append(fileJson)\n",
    "    return steam_review_list\n",
    "\n",
    "steam_review_list = get_steam_review_json()\n",
    "df = pd.json_normalize(steam_review_list)\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
